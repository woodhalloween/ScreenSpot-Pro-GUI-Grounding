# SUZAK -SFT&GRPO-

このリポジトリには、Qwen2.5VL-7BモデルをGRPO（Group Relative Policy Optimization）手法で学習するためのコードが含まれています。主にLambda CloudのH100インスタンスでの使用を想定しています。

## 目次

1. [概要](#概要)
2. [環境要件](#環境要件)
3. [Lambda Cloudでの学習環境セットアップ](#lambda-cloudでの学習環境セットアップ)
4. [学習の実行](#学習の実行)
5. [評価方法](#評価方法)
6. [トラブルシューティング](#トラブルシューティング)

## 概要

このプロジェクトでは、Qwen2.5VL-7Bモデルに対してGRPO手法を適用し、視覚的推論タスク（CLEVRなど）でのパフォーマンスを向上させることを目的としています。GRPOは、数学的推論能力の向上に効果的なアプローチです。

## 環境要件

Qwen2.5VL 7Bモデルを学習するには、少なくとも以下のハードウェアが必要です：

- H100(80GB VRAM)

## Lambda Cloudでの学習環境セットアップ

### 1. インスタンスのセットアップ

#### 1.1 SSH鍵の設定（必須）

インスタンスを起動する前に、SSH鍵の設定が必要です：

1. Lambda Cloudコンソールで「SSH keys」ページに移動します
2. 「Add SSH Key」をクリックします
3. 既存のSSH鍵を持っている場合：
   - テキスト入力ボックスに公開鍵を貼り付けます
   - 鍵の名前を入力して「Add SSH key」をクリックします
4. 新しいSSH鍵を生成する場合：
   - 「Generate a new SSH key」をクリックします
   - 鍵の名前を入力して「Create」をクリックします
   - 鍵がダウンロードされるので、安全な場所に保存してください

#### 1.2 インスタンスの選択と起動

1. Lambda Cloudコンソールの「Instances」ページから「Launch Instance」をクリックします
2. H100 GPUが搭載されたインスタンスタイプを選択します
3. SSH鍵を選択します（先ほど追加した鍵）
4. 必要に応じて永続ストレージを設定します
   - **注意**: データを保持したい場合は必須です。インスタンス終了後にデータを復元することはできません

### 2. インスタンスへの接続

#### 2.1 SSH接続（通常の方法）

インスタンスが起動したら、SSHで接続します：

bash
ssh -i '~/path/to/your/private/key' ubuntu@<インスタンスのIPアドレス>

IPアドレスはLambda Cloudコンソールの「Instances」ページで確認できます。

#### 2.1.1 SSH Config設定による簡易接続

SSH設定ファイルを使用すると、毎回長いコマンドを入力せずに簡単にインスタンスに接続できます：

1. ローカルマシンでSSH設定ファイルを作成または編集します：

bash
nano ~/.ssh/config

2. 以下の内容を追加します（必要に応じて値を変更）：

Host lambda
    HostName <インスタンスのIPアドレス>
    User ubuntu
    IdentityFile ~/.ssh/<プライベートキーファイル名>
    ServerAliveInterval 60
    StrictHostKeyChecking no

3. ファイルを保存して終了（`Ctrl+O`, `Enter`, `Ctrl+X`）

4. これで、以下のシンプルなコマンドでインスタンスに接続できます：

bash
ssh lambda-cloud

インスタンスのIPアドレスが変わった場合は、`~/.ssh/config`ファイルの`HostName`値を更新するだけで済みます。

#### 2.2 JupyterLabを使用する場合

1. Lambda Cloudコンソールの「Instances」ページで、該当インスタンスの「Cloud IDE」列にある「Launch」ボタンをクリックします
2. ブラウザで直接JupyterLabに接続できます

#### 2.3 追加のSSH鍵を設定する場合

複数のデバイスからアクセスする場合など、追加のSSH鍵を設定できます：

bash
# インスタンスにSSH接続後、以下を実行
echo 'あなたの追加する公開鍵' >> ~/.ssh/authorized_keys

### 3. 学習環境のセットアップ

インスタンスに接続したら、以下の手順で環境を準備します：

#### 3.1 コードの取得（方法1：GitHubからクローン）

bash
# リポジトリをクローン
git clone https://github.com/あなたのユーザー名/sft-grpo-trainer.git
cd sft-grpo-trainer

#### 3.2 コードの取得（方法2：ローカルからファイルを転送）

GitHubからのクローンの代わりに、ローカルマシンからSCPを使ってファイルを転送することもできます：

bash
# ローカルマシンで実行（Lambdaインスタンスではなく）
# 方法1: IPアドレスを直接指定する場合
scp -r /path/to/local/sft-grpo-trainer ubuntu@<インスタンスのIPアドレス>:~/

# 方法2: SSH設定ファイル(~/.ssh/config)を使用している場合
# 上記の「2.1.1 SSH Config設定による簡易接続」を設定済みの場合
scp -r /path/to/local/sft-grpo-trainer lambda-cloud:~/

# 転送後、Lambda上で以下を実行
cd sft-grpo-trainer

#### 3.3 環境のセットアップ

bash
# 1. Conda環境のセットアップ（推奨）
conda create -n suzak python=3.11
conda activate suzak

# 2. セットアップスクリプトの実行（必須）
bash setup.sh

# 3. 環境変数の設定
cp .env.example .env
# .envファイルを編集して適切な値を設定
# 必ず以下の項目を設定してください：
# - HF_TOKEN（Hugging Faceのトークン）
# - WANDB_API_KEY（Weights & Biasesのトークン）
# - WANDB_PROJECT（プロジェクト名）
# - WANDB_ENTITY（ユーザー名またはチーム名）
# - HUB_MODEL_ID（モデルを保存するHugging Faceのリポジトリ名）

セットアップスクリプトが実行する主な内容：
- suzakパッケージの開発モードでのインストール
- Weights & Biases (wandb)、tensorboardxのインストール
- Qwen VL関連ユーティリティとtorchvisionのインストール
- Flash Attentionのインストール（CUDA環境との互換性が重要）
- Hugging Face Hubとpython-dotenvのインストール
- vLLMのインストール（バージョン0.7.2）
- 特定バージョンのTransformersライブラリのインストール
- 開発ツール（ruff、pre-commit）のインストール
- tf-kerasのインストール（Transformersライブラリの互換性のため）

また、Flash Attentionを使用する場合、CUDAバージョンとの互換性が重要です。環境によっては以下の環境変数を設定してFlash Attentionを無効化する必要があります：

bash
export TRANSFORMERS_NO_FLASH_ATTENTION=1

これは`run_grpo_clevr.sh`スクリプトを修正することでも設定できます：

bash
# Hugging Face認証セクションの直後に追加
export TRANSFORMERS_NO_FLASH_ATTENTION=1

# attn_implementationパラメータを変更
--attn_implementation eager \

# データセットをダウンロード（必要に応じて）
bash
# 例: huggingface-cli download dataset_name --repo-type=dataset --local-dir=./clevr_cogen_a_train

#### 3.4 ローカルの.envファイルをLambdaインスタンスに転送する方法

既にローカルで.envファイルを作成している場合、SCPコマンドを使用してLambdaインスタンスに転送できます：

bash
# ローカルのターミナルで実行（Lambdaインスタンスには接続しない状態で）
scp -i '~/path/to/your/private/key' /path/to/local/.env ubuntu@<インスタンスのIPアドレス>:~/sft-grpo-trainer/

または、リポジトリをクローンした後にSCPで転送する場合：

bash
# ローカルのターミナルで実行
scp -i '~/path/to/your/private/key' /path/to/local/.env ubuntu@<インスタンスのIPアドレス>:~/sft-grpo-trainer/

別の方法として、Lambdaインスタンス上で直接ファイルを作成することもできます：

bash
# Lambdaインスタンス上で実行
nano .env
# ローカルの.envファイルの内容をコピー＆ペーストし、Ctrl+O, Enterで保存、Ctrl+Xで終了

転送後、.envファイルが正しく設定されているか確認します：

bash
# Lambdaインスタンス上で実行
cat .env

環境変数を読み込むには、以下のコマンドを実行します：

bash
# Lambdaインスタンス上で実行
set -a
source .env
set +a

# 環境変数が正しく設定されたか確認
echo $HF_TOKEN
echo $WANDB_API_KEY

## 学習の実行

### 1. 学習スクリプトの実行

bash
# 学習スクリプトを実行
bash src/scripts/run_grpo_clevr.sh

このスクリプトは、以下の処理を行います：
- 環境変数の読み込み（.envファイル）
- WandB（Weights & Biases）の設定
- 出力ディレクトリの作成
- torchrunを使用したGRPO学習の実行

### 2. 学習の進捗確認

学習の進捗は以下の方法で確認できます：

1. WandBダッシュボード（[wandb.ai](https://wandb.ai/)）にアクセスして、リアルタイムの学習メトリクスを確認
2. ログファイル（`./clevr_training_log.txt`）の内容を確認

### 3. 学習済みモデルの保存

学習済みモデルは以下の場所に保存されます：
- ローカル: 指定した出力ディレクトリ（`./output/qwen25vl-7b-grpo-clevr`）
- リモート: Hugging Faceハブ（`--push_to_hub true`オプションが設定されている場合）

### 4. インスタンスの停止方法（重要）

**警告**: インスタンスを停止しないと課金が継続されます。以下のいずれかの方法で確実に停止してください：

#### 4.1 コンソールから停止

1. Lambda Cloudコンソールの「Instances」ページに移動します
2. 該当インスタンスの行で「Actions」列から「Terminate」を選択します
3. 確認ダイアログで「Terminate」をクリックします

#### 4.2 APIから停止

Lambda Cloud APIを使用して停止することもできます：

bash
curl -X DELETE \
  -H "Authorization: Bearer YOUR_API_KEY" \
  https://cloud.lambdalabs.com/api/v1/instance/YOUR_INSTANCE_ID

## 重要な注意事項

1. **データバックアップ**: インスタンスを終了する前に、学習済みモデルや重要なデータをバックアップしてください。以下の方法があります：
   - Hugging Faceにモデルをアップロード（`run_grpo_clevr.sh`に設定済み）
   - `rsync`などを使用してローカルマシンにデータをコピー：
     
bash
     rsync -avz -e "ssh -i /path/to/key" ubuntu@<インスタンスIP>:/path/to/model/files /local/destination
     


2. **一時停止不可**: 現在Lambdaでは、インスタンスを一時停止（pause）することはできません。終了（terminate）のみが可能です。

3. **Ubuntu更新禁止**: `sudo do-release-upgrade`を実行してUbuntuをアップグレードしないでください。JupyterLabが機能しなくなります。

4. **永続ストレージ**: 長期間にわたる学習の場合、永続ストレージを使用することを検討してください。これにより、インスタンスを終了しても重要なデータを保持できます。

## トラブルシューティング

- **SSHで接続できない場合**：
  - SSH鍵のパスと権限を確認（`chmod 600 /path/to/key`）
  - インスタンスのIPアドレスが正しいか確認
  - Lambda Cloudのファイアウォール設定を確認

- **Flash Attentionの互換性エラーが発生した場合**：
  - 以下のようなエラーが表示される場合は、Flash Attentionの互換性問題が発生しています：
    

    ImportError: flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZNK3c1011StorageImpl27throw_data_ptr_access_errorEv
    

  - 解決方法1: Flash Attentionを完全に削除する
    
bash
    pip uninstall -y flash-attn
    

  - 解決方法2: 環境変数を設定してFlash Attentionを無効化する
    
bash
    export TRANSFORMERS_NO_FLASH_ATTENTION=1
    

  - 解決方法3: スクリプトのパラメータを変更する
    
bash
    # run_grpo_clevr.shを編集し、以下の行を
    --attn_implementation flash_attention_2 \
    # 以下に変更
    --attn_implementation eager \
    

  - 解決方法4: 互換性のあるPyTorchとFlash Attentionの組み合わせを使用する
    
bash
    # 新しい環境を作成
    conda create -n suzak_clean python=3.11 -y
    conda activate suzak_clean
    # Flash Attentionと互換性のあるバージョンをインストール
    pip install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu121
    pip install flash-attn==2.7.4.post1
    


- **メモリ不足エラー（OOM）が発生した場合**：
  - エラーメッセージ「CUDA out of memory」が表示される場合は、以下の手順で対処します
  
  - 手順1: すべてのPythonプロセスを終了してメモリをクリア
    
bash
    # すべてのPythonプロセスを終了
    pkill -9 python
    
    # GPUメモリ状態の確認
    nvidia-smi
    

  
  - 手順2: `run_grpo_clevr.sh`スクリプトのパラメータを調整
    
bash
    # 以下のパラメータを変更
    --per_device_train_batch_size 1     # バッチサイズを小さく
    --gradient_accumulation_steps 16    # 勾配蓄積ステップを増やす（例: 8→16）
    --max_pixels 200704                 # ピクセル数を減らす（例: 401408→200704）
    --num_generations 2                 # 生成数を減らす（例: 4→2）
    

  
  - 手順3: 環境変数を設定してメモリ割り当てを最適化
    
bash
    export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    

  
  - 手順4: より厳しいOOM対策が必要な場合（H100でも）
    
bash
    # DeepSpeedを使用する
    # まずds_config.jsonファイルを作成
    cat > ds_config.json << 'EOL'
    {
      "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
          "device": "cpu"
        },
        "contiguous_gradients": true,
        "overlap_comm": true
      },
      "bf16": {
        "enabled": true
      }
    }
    EOL
    
    # DeepSpeedパラメータを追加
    --deepspeed ds_config.json
    


- **学習が不安定な場合**：
  - 学習率を下げる（例：`--learning_rate 5e-7`を追加）
  - 温度パラメータを調整する（例：`--temperature 0.8`を追加）

- **Kerasの互換性エラー**：
  - `pip install tf-keras`を実行

## 評価方法

### SuperCLEVR

bash
cd ./src/eval
wget https://www.cs.jhu.edu/~zhuowan/zhuowan/SuperCLEVR/to_be_released/images.zip
unzip images.zip

python test_qwen2vl_counting_superclevr.py \
    --model_path <PATH-TO-YOUR-MODEL> \
    --batch_size 1

# 参考スコア: 
# Qwen2VL-2B-Instruct: 48.0%
# Qwen2VL-2B-Instruct-GRPO-100step: 82.5%
# Qwen2.5VL-3B-Instruct: 55.0%
# Qwen2.5VL-3B-Instruct-GRPO-100step: 89.5%

### GEOQA

```bash
# テスト用画像の準備
cd ./src/eval
git lfs install
git clone https://huggingface.co/datasets/Luckyjhg/Geo170K
cd Geo170K
unzip images.zip

# 評価スクリプト
python test_qwen2vl_geoqa.py \
    --model_path <PATH-TO-YOUR-MODEL> \
    --batch_size 1

# 参考スコア: 
# Qwen2VL-7B-Instruct: 30.63%
# Qwen2VL-7B-Instruct-GRPO-2epochs: 38.72%
# Qwen2.5VL-3B-Instruct: 35.41%
# Qwen2.5VL-3B-Instruct-GRPO-1epochs: 47.48%
